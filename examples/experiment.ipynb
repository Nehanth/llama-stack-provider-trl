{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "\n",
    "# Base URL for the Llama Stack client API\n",
    "# The client connects to the remote TRL service for training\n",
    "base_url = \"http://127.0.0.1:8321\"\n",
    "\n",
    "# Remote TRL service runs on http://localhost:8080\n",
    "# Client forwards training requests to the remote service\n",
    "remote_service_url = \"http://localhost:8080\"\n",
    "\n",
    "# Headers for GET requests (retrieving data)\n",
    "headers_get = {\n",
    "    \"accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Headers for POST requests (sending data)\n",
    "headers_post = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Upload Status: 200\n",
      "Dataset Upload Response: {'identifier': 'test-dpo-dataset-remote-50', 'provider_resource_id': 'test-dpo-dataset-remote-50', 'provider_id': 'localfs', 'type': 'dataset', 'owner': {'principal': '', 'attributes': {}}, 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is machine learning?', 'chosen': 'Machine learning is a branch of AI where algorithms learn from data to make predictions or decisions.', 'rejected': 'Machine learning is just computers doing math stuff.'}, {'prompt': 'Write a hello world program', 'chosen': 'Here is a simple hello world program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```', 'rejected': 'print hello world'}, {'prompt': 'Explain fine-tuning', 'chosen': 'Fine-tuning adapts a pre-trained model to a specific task by additional training on task-specific data.', 'rejected': 'Fine-tuning is training more.'}, {'prompt': 'What is deep learning?', 'chosen': 'Deep learning is a subset of machine learning using neural networks with multiple layers to learn complex patterns.', 'rejected': 'Deep learning is big neural networks.'}, {'prompt': 'Explain supervised learning', 'chosen': 'Supervised learning trains models using labeled datasets where the correct output is provided for each input.', 'rejected': 'Supervised learning means learning with supervision.'}, {'prompt': 'What is unsupervised learning?', 'chosen': 'Unsupervised learning involves training on unlabeled data to discover hidden structures or patterns.', 'rejected': 'Unsupervised learning has no teacher.'}, {'prompt': 'Define reinforcement learning', 'chosen': 'Reinforcement learning trains agents through trial and error by rewarding desirable actions and penalizing mistakes.', 'rejected': 'Reinforcement learning is learning by doing stuff.'}, {'prompt': 'Explain overfitting', 'chosen': 'Overfitting occurs when a model learns the training data too well, including its noise, reducing its generalization on new data.', 'rejected': 'Overfitting means memorizing the data.'}, {'prompt': 'What is natural language processing?', 'chosen': 'Natural language processing enables computers to understand, interpret, and generate human language.', 'rejected': 'NLP is about computers talking.'}, {'prompt': 'Explain gradient descent', 'chosen': 'Gradient descent is an optimization algorithm that iteratively updates model parameters to minimize loss by moving in the direction of the negative gradient.', 'rejected': 'Gradient descent moves the model slowly to better values.'}, {'prompt': 'Explain transfer learning', 'chosen': 'Transfer learning leverages knowledge from a pre-trained model to solve a related task with less data and computation.', 'rejected': 'Transfer learning copies models to new tasks.'}, {'prompt': 'What is computer vision?', 'chosen': 'Computer vision allows machines to interpret and analyze visual information from the world.', 'rejected': 'Computer vision is machines looking at stuff.'}, {'prompt': 'What is artificial general intelligence?', 'chosen': 'Artificial general intelligence refers to highly autonomous systems that can outperform humans at most economically valuable work.', 'rejected': 'AGI is AI that can do everything.'}, {'prompt': 'What is data augmentation?', 'chosen': 'Data augmentation artificially increases the size of training data by generating modified versions of existing data.', 'rejected': 'Data augmentation makes more data.'}, {'prompt': 'Explain tokenization', 'chosen': 'Tokenization is the process of breaking text into smaller units, such as words or subwords, to prepare it for model processing.', 'rejected': 'Tokenization cuts up sentences.'}, {'prompt': 'Explain large language models', 'chosen': 'Large language models are trained on massive datasets and can generate coherent text and understand complex language patterns.', 'rejected': 'LLMs are just huge models that write stuff.'}, {'prompt': 'What is a transformer model?', 'chosen': 'Transformer models use self-attention mechanisms to process input sequences in parallel, enabling efficient and scalable learning.', 'rejected': 'Transformers are big models that pay attention.'}, {'prompt': 'Explain self-attention', 'chosen': 'Self-attention allows a model to weigh different parts of the input sequence when processing a token, enabling better context understanding.', 'rejected': 'Self-attention looks at itself.'}, {'prompt': 'What is zero-shot learning?', 'chosen': \"Zero-shot learning allows models to handle tasks they weren't explicitly trained on by leveraging general knowledge.\", 'rejected': 'Zero-shot means no training needed.'}, {'prompt': 'What is prompt engineering?', 'chosen': 'Prompt engineering involves crafting input prompts to elicit desired responses from language models.', 'rejected': 'Prompt engineering is asking the model stuff.'}, {'prompt': 'Explain hallucination in LLMs', 'chosen': 'Hallucination refers to language models generating plausible-sounding but factually incorrect or fabricated outputs.', 'rejected': 'Hallucination is making up stuff.'}, {'prompt': 'What is alignment in AI?', 'chosen': 'AI alignment ensures models behave in ways that match human values and intentions.', 'rejected': 'Alignment is making AI not dangerous.'}, {'prompt': 'What is multi-modal AI?', 'chosen': 'Multi-modal AI can process and reason across multiple types of data like text, images, audio, and video.', 'rejected': 'Multi-modal AI does many things at once.'}, {'prompt': 'Explain RAG (retrieval-augmented generation)', 'chosen': 'RAG combines retrieval from knowledge bases with generative models to improve factual accuracy in outputs.', 'rejected': 'RAG gets facts from search.'}, {'prompt': 'What is LoRA?', 'chosen': 'LoRA is a fine-tuning technique that adds trainable low-rank matrices to pre-trained model weights, enabling efficient adaptation.', 'rejected': 'LoRA is small changes to big models.'}, {'prompt': 'What is quantization?', 'chosen': 'Quantization reduces model size and speeds up inference by representing weights with lower-precision numbers.', 'rejected': 'Quantization makes models smaller.'}, {'prompt': 'What is model distillation?', 'chosen': 'Distillation transfers knowledge from a large model to a smaller one, preserving performance while reducing size and computation.', 'rejected': 'Distillation is shrinking models.'}, {'prompt': 'Explain chain-of-thought prompting', 'chosen': 'Chain-of-thought prompting encourages models to explain reasoning steps before answering, improving accuracy on complex tasks.', 'rejected': 'It makes the model think out loud.'}, {'prompt': 'Explain temperature in language models', 'chosen': 'Temperature controls randomness in model output â€” higher values generate more diverse responses, lower values make outputs more deterministic.', 'rejected': 'Temperature makes answers more random.'}, {'prompt': 'What is top-k sampling?', 'chosen': 'Top-k sampling limits token selection to the k most probable tokens, reducing randomness and improving output quality.', 'rejected': 'Top-k picks from the best options.'}, {'prompt': 'What is beam search?', 'chosen': 'Beam search explores multiple output sequences simultaneously, selecting the most probable complete sequence.', 'rejected': 'Beam search tries several paths.'}, {'prompt': 'What is token limit?', 'chosen': 'Token limit refers to the maximum number of tokens a model can process in a single input or output sequence.', 'rejected': 'Token limit is how long the model can read.'}, {'prompt': 'What is RLHF?', 'chosen': 'Reinforcement Learning with Human Feedback fine-tunes models by optimizing based on human preference scores.', 'rejected': 'RLHF is when humans give feedback.'}, {'prompt': 'Explain pre-training vs fine-tuning', 'chosen': 'Pre-training involves general unsupervised learning on large corpora; fine-tuning adapts models to specific tasks using supervised data.', 'rejected': 'Pre-training is first, fine-tuning is second.'}, {'prompt': 'What is a reward model?', 'chosen': 'A reward model predicts the desirability of model outputs and guides optimization during preference-based training.', 'rejected': 'Reward model gives scores.'}, {'prompt': 'What is synthetic data?', 'chosen': 'Synthetic data is artificially generated data that mimics real-world data, often used to augment training datasets.', 'rejected': 'Synthetic data is fake data.'}, {'prompt': 'Explain few-shot learning', 'chosen': 'Few-shot learning enables models to generalize to new tasks with very few examples by leveraging prior knowledge.', 'rejected': 'Few-shot is learning from a few examples.'}, {'prompt': 'What is model drift?', 'chosen': \"Model drift occurs when a model's performance degrades over time due to changes in data distributions.\", 'rejected': 'Model drift means the model gets worse.'}, {'prompt': 'Explain evaluation benchmarks', 'chosen': 'Evaluation benchmarks provide standardized tasks to assess model performance across various domains.', 'rejected': 'Benchmarks test models.'}, {'prompt': 'What is instruction tuning?', 'chosen': 'Instruction tuning fine-tunes models to follow explicit natural language instructions for better task generalization.', 'rejected': 'Instruction tuning teaches models to follow commands.'}, {'prompt': 'Explain safety in LLM deployment', 'chosen': 'Safety in LLM deployment involves techniques to prevent harmful, biased, or dangerous outputs.', 'rejected': 'Safety means not letting AI say bad stuff.'}, {'prompt': 'What is multi-turn dialogue?', 'chosen': 'Multi-turn dialogue refers to conversations where the model maintains context across multiple user interactions.', 'rejected': 'Multi-turn is talking back and forth.'}, {'prompt': 'What is hallucination detection?', 'chosen': 'Hallucination detection methods aim to identify when a model generates factually incorrect outputs.', 'rejected': 'It spots made up stuff.'}, {'prompt': 'What is model alignment research?', 'chosen': 'Model alignment research focuses on ensuring AI systems behave consistently with human values and goals.', 'rejected': 'Alignment research makes AI safe.'}, {'prompt': 'What is model interpretability?', 'chosen': 'Interpretability involves techniques that make model decisions understandable to humans.', 'rejected': 'Interpretability explains what AI is doing.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Expanded DPO preference dataset with 50 examples'}}\n"
     ]
    }
   ],
   "source": [
    "# Upload a DPO dataset for remote training\n",
    "# This creates a preference dataset that will be sent to the remote TRL service\n",
    "\n",
    "url_upload_dataset = f\"{base_url}/v1/datasets\"\n",
    "\n",
    "# Define the dataset payload with preference pairs\n",
    "dataset_payload = {\n",
    "    \"dataset_id\": \"test-dpo-dataset-remote-50\",\n",
    "    \"purpose\": \"post-training/messages\",             \n",
    "    \"dataset_type\": \"preference\",                    \n",
    "    \"source\": {\n",
    "        \"type\": \"rows\",                              \n",
    "        \"rows\": [\n",
    "            {\"prompt\": \"What is machine learning?\", \"chosen\": \"Machine learning is a branch of AI where algorithms learn from data to make predictions or decisions.\", \"rejected\": \"Machine learning is just computers doing math stuff.\"},\n",
    "            {\"prompt\": \"Write a hello world program\", \"chosen\": \"Here is a simple hello world program in Python:\\n\\n```python\\nprint(\\\"Hello, World!\\\")\\n```\", \"rejected\": \"print hello world\"},\n",
    "            {\"prompt\": \"Explain fine-tuning\", \"chosen\": \"Fine-tuning adapts a pre-trained model to a specific task by additional training on task-specific data.\", \"rejected\": \"Fine-tuning is training more.\"},\n",
    "            {\"prompt\": \"What is deep learning?\", \"chosen\": \"Deep learning is a subset of machine learning using neural networks with multiple layers to learn complex patterns.\", \"rejected\": \"Deep learning is big neural networks.\"},\n",
    "            {\"prompt\": \"Explain supervised learning\", \"chosen\": \"Supervised learning trains models using labeled datasets where the correct output is provided for each input.\", \"rejected\": \"Supervised learning means learning with supervision.\"},\n",
    "            {\"prompt\": \"What is unsupervised learning?\", \"chosen\": \"Unsupervised learning involves training on unlabeled data to discover hidden structures or patterns.\", \"rejected\": \"Unsupervised learning has no teacher.\"},\n",
    "            {\"prompt\": \"Define reinforcement learning\", \"chosen\": \"Reinforcement learning trains agents through trial and error by rewarding desirable actions and penalizing mistakes.\", \"rejected\": \"Reinforcement learning is learning by doing stuff.\"},\n",
    "            {\"prompt\": \"Explain overfitting\", \"chosen\": \"Overfitting occurs when a model learns the training data too well, including its noise, reducing its generalization on new data.\", \"rejected\": \"Overfitting means memorizing the data.\"},\n",
    "            {\"prompt\": \"What is natural language processing?\", \"chosen\": \"Natural language processing enables computers to understand, interpret, and generate human language.\", \"rejected\": \"NLP is about computers talking.\"},\n",
    "            {\"prompt\": \"Explain gradient descent\", \"chosen\": \"Gradient descent is an optimization algorithm that iteratively updates model parameters to minimize loss by moving in the direction of the negative gradient.\", \"rejected\": \"Gradient descent moves the model slowly to better values.\"},\n",
    "            {\"prompt\": \"Explain transfer learning\", \"chosen\": \"Transfer learning leverages knowledge from a pre-trained model to solve a related task with less data and computation.\", \"rejected\": \"Transfer learning copies models to new tasks.\"},\n",
    "            {\"prompt\": \"What is computer vision?\", \"chosen\": \"Computer vision allows machines to interpret and analyze visual information from the world.\", \"rejected\": \"Computer vision is machines looking at stuff.\"},\n",
    "            {\"prompt\": \"What is artificial general intelligence?\", \"chosen\": \"Artificial general intelligence refers to highly autonomous systems that can outperform humans at most economically valuable work.\", \"rejected\": \"AGI is AI that can do everything.\"},\n",
    "            {\"prompt\": \"What is data augmentation?\", \"chosen\": \"Data augmentation artificially increases the size of training data by generating modified versions of existing data.\", \"rejected\": \"Data augmentation makes more data.\"},\n",
    "            {\"prompt\": \"Explain tokenization\", \"chosen\": \"Tokenization is the process of breaking text into smaller units, such as words or subwords, to prepare it for model processing.\", \"rejected\": \"Tokenization cuts up sentences.\"},\n",
    "            {\"prompt\": \"Explain large language models\", \"chosen\": \"Large language models are trained on massive datasets and can generate coherent text and understand complex language patterns.\", \"rejected\": \"LLMs are just huge models that write stuff.\"},\n",
    "            {\"prompt\": \"What is a transformer model?\", \"chosen\": \"Transformer models use self-attention mechanisms to process input sequences in parallel, enabling efficient and scalable learning.\", \"rejected\": \"Transformers are big models that pay attention.\"},\n",
    "            {\"prompt\": \"Explain self-attention\", \"chosen\": \"Self-attention allows a model to weigh different parts of the input sequence when processing a token, enabling better context understanding.\", \"rejected\": \"Self-attention looks at itself.\"},\n",
    "            {\"prompt\": \"What is zero-shot learning?\", \"chosen\": \"Zero-shot learning allows models to handle tasks they weren't explicitly trained on by leveraging general knowledge.\", \"rejected\": \"Zero-shot means no training needed.\"},\n",
    "            {\"prompt\": \"What is prompt engineering?\", \"chosen\": \"Prompt engineering involves crafting input prompts to elicit desired responses from language models.\", \"rejected\": \"Prompt engineering is asking the model stuff.\"},\n",
    "            {\"prompt\": \"Explain hallucination in LLMs\", \"chosen\": \"Hallucination refers to language models generating plausible-sounding but factually incorrect or fabricated outputs.\", \"rejected\": \"Hallucination is making up stuff.\"},\n",
    "            {\"prompt\": \"What is alignment in AI?\", \"chosen\": \"AI alignment ensures models behave in ways that match human values and intentions.\", \"rejected\": \"Alignment is making AI not dangerous.\"},\n",
    "            {\"prompt\": \"What is multi-modal AI?\", \"chosen\": \"Multi-modal AI can process and reason across multiple types of data like text, images, audio, and video.\", \"rejected\": \"Multi-modal AI does many things at once.\"},\n",
    "            {\"prompt\": \"Explain RAG (retrieval-augmented generation)\", \"chosen\": \"RAG combines retrieval from knowledge bases with generative models to improve factual accuracy in outputs.\", \"rejected\": \"RAG gets facts from search.\"},\n",
    "            {\"prompt\": \"What is LoRA?\", \"chosen\": \"LoRA is a fine-tuning technique that adds trainable low-rank matrices to pre-trained model weights, enabling efficient adaptation.\", \"rejected\": \"LoRA is small changes to big models.\"},\n",
    "            {\"prompt\": \"What is quantization?\", \"chosen\": \"Quantization reduces model size and speeds up inference by representing weights with lower-precision numbers.\", \"rejected\": \"Quantization makes models smaller.\"},\n",
    "            {\"prompt\": \"What is model distillation?\", \"chosen\": \"Distillation transfers knowledge from a large model to a smaller one, preserving performance while reducing size and computation.\", \"rejected\": \"Distillation is shrinking models.\"},\n",
    "            {\"prompt\": \"Explain chain-of-thought prompting\", \"chosen\": \"Chain-of-thought prompting encourages models to explain reasoning steps before answering, improving accuracy on complex tasks.\", \"rejected\": \"It makes the model think out loud.\"},\n",
    "            {\"prompt\": \"Explain temperature in language models\", \"chosen\": \"Temperature controls randomness in model output â€” higher values generate more diverse responses, lower values make outputs more deterministic.\", \"rejected\": \"Temperature makes answers more random.\"},\n",
    "            {\"prompt\": \"What is top-k sampling?\", \"chosen\": \"Top-k sampling limits token selection to the k most probable tokens, reducing randomness and improving output quality.\", \"rejected\": \"Top-k picks from the best options.\"},\n",
    "            {\"prompt\": \"What is beam search?\", \"chosen\": \"Beam search explores multiple output sequences simultaneously, selecting the most probable complete sequence.\", \"rejected\": \"Beam search tries several paths.\"},\n",
    "            {\"prompt\": \"What is token limit?\", \"chosen\": \"Token limit refers to the maximum number of tokens a model can process in a single input or output sequence.\", \"rejected\": \"Token limit is how long the model can read.\"},\n",
    "            {\"prompt\": \"What is RLHF?\", \"chosen\": \"Reinforcement Learning with Human Feedback fine-tunes models by optimizing based on human preference scores.\", \"rejected\": \"RLHF is when humans give feedback.\"},\n",
    "            {\"prompt\": \"Explain pre-training vs fine-tuning\", \"chosen\": \"Pre-training involves general unsupervised learning on large corpora; fine-tuning adapts models to specific tasks using supervised data.\", \"rejected\": \"Pre-training is first, fine-tuning is second.\"},\n",
    "            {\"prompt\": \"What is a reward model?\", \"chosen\": \"A reward model predicts the desirability of model outputs and guides optimization during preference-based training.\", \"rejected\": \"Reward model gives scores.\"},\n",
    "            {\"prompt\": \"What is synthetic data?\", \"chosen\": \"Synthetic data is artificially generated data that mimics real-world data, often used to augment training datasets.\", \"rejected\": \"Synthetic data is fake data.\"},\n",
    "            {\"prompt\": \"Explain few-shot learning\", \"chosen\": \"Few-shot learning enables models to generalize to new tasks with very few examples by leveraging prior knowledge.\", \"rejected\": \"Few-shot is learning from a few examples.\"},\n",
    "            {\"prompt\": \"What is model drift?\", \"chosen\": \"Model drift occurs when a model's performance degrades over time due to changes in data distributions.\", \"rejected\": \"Model drift means the model gets worse.\"},\n",
    "            {\"prompt\": \"Explain evaluation benchmarks\", \"chosen\": \"Evaluation benchmarks provide standardized tasks to assess model performance across various domains.\", \"rejected\": \"Benchmarks test models.\"},\n",
    "            {\"prompt\": \"What is instruction tuning?\", \"chosen\": \"Instruction tuning fine-tunes models to follow explicit natural language instructions for better task generalization.\", \"rejected\": \"Instruction tuning teaches models to follow commands.\"},\n",
    "            {\"prompt\": \"Explain safety in LLM deployment\", \"chosen\": \"Safety in LLM deployment involves techniques to prevent harmful, biased, or dangerous outputs.\", \"rejected\": \"Safety means not letting AI say bad stuff.\"},\n",
    "            {\"prompt\": \"What is multi-turn dialogue?\", \"chosen\": \"Multi-turn dialogue refers to conversations where the model maintains context across multiple user interactions.\", \"rejected\": \"Multi-turn is talking back and forth.\"},\n",
    "            {\"prompt\": \"What is hallucination detection?\", \"chosen\": \"Hallucination detection methods aim to identify when a model generates factually incorrect outputs.\", \"rejected\": \"It spots made up stuff.\"},\n",
    "            {\"prompt\": \"What is model alignment research?\", \"chosen\": \"Model alignment research focuses on ensuring AI systems behave consistently with human values and goals.\", \"rejected\": \"Alignment research makes AI safe.\"},\n",
    "            {\"prompt\": \"What is model interpretability?\", \"chosen\": \"Interpretability involves techniques that make model decisions understandable to humans.\", \"rejected\": \"Interpretability explains what AI is doing.\"}\n",
    "        ]\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"provider_id\": \"localfs\",                    \n",
    "        \"description\": \"Expanded DPO preference dataset with 50 examples\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Send the POST request to upload the dataset\n",
    "response_dataset = requests.post(url_upload_dataset, headers=headers_post, json=dataset_payload)\n",
    "print(\"Dataset Upload Status:\", response_dataset.status_code)\n",
    "print(\"Dataset Upload Response:\", response_dataset.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 45\u001b[0m\n\u001b[1;32m      3\u001b[0m url_train_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/v1/post-training/preference-optimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m train_model_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob_uuid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremote-dpo-training-granite\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mibm-granite/granite-3.3-2b-base\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Still using smaller model for quicker experiments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogger_config\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}\n\u001b[1;32m     43\u001b[0m }\n\u001b[0;32m---> 45\u001b[0m response_train_model \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_train_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_model_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote Training Status:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response_train_model\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote Training Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response_train_model\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/ilab_stuff/llama-stack-provider-trl/.venv/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ilab_stuff/llama-stack-provider-trl/.venv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ilab_stuff/llama-stack-provider-trl/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/ilab_stuff/llama-stack-provider-trl/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/ilab_stuff/llama-stack-provider-trl/.venv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/ilab_stuff/llama-stack-provider-trl/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/ilab_stuff/llama-stack-provider-trl/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/ilab_stuff/llama-stack-provider-trl/.venv/lib/python3.10/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Submit DPO training job to remote TRL service\n",
    "\n",
    "url_train_model = f\"{base_url}/v1/post-training/preference-optimize\"\n",
    "\n",
    "train_model_data = {\n",
    "    \"job_uuid\": \"remote-dpo-training-granite\",\n",
    "    \"model\": \"ibm-granite/granite-3.3-2b-base\",  # Still using smaller model for quicker experiments\n",
    "    \"finetuned_model\": \"dpo-granite-3.3-2b-base-remote\",\n",
    "    \"checkpoint_dir\": \"../dpo_checkpoints\",\n",
    "    \n",
    "    # LoRA config (only for schema validation passthrough - actual provider runs DPO)\n",
    "    \"algorithm_config\": {\n",
    "        \"type\": \"LoRA\",\n",
    "        \"lora_attn_modules\": [\"attn\"],\n",
    "        \"apply_lora_to_mlp\": False,\n",
    "        \"apply_lora_to_output\": False,\n",
    "        \"rank\": 16,\n",
    "        \"alpha\": 32\n",
    "    },\n",
    "\n",
    "    \"training_config\": {    \n",
    "        \"n_epochs\": 3,                           # Increase epochs for better learning\n",
    "        \"max_steps_per_epoch\": 100,              # More steps per epoch for larger dataset\n",
    "        \"gradient_accumulation_steps\": 2,        # Effective batch size = batch_size * accumulation\n",
    "        \"data_config\": {\n",
    "            \"dataset_id\": \"test-dpo-dataset-remote-50\",\n",
    "            \"batch_size\": 4,                     # Bigger batch helps stability\n",
    "            \"shuffle\": True,\n",
    "            \"data_format\": \"instruct\"\n",
    "        },\n",
    "        \"optimizer_config\": {\n",
    "            \"optimizer_type\": \"adamw\",\n",
    "            \"lr\": 5e-5,                          # Higher learning rate works better for DPO\n",
    "            \"lr_scheduler_type\": \"cosine\",       # Cosine often works better for preference optimization\n",
    "            \"warmup_steps\": 50,                  # Better warmup for stability\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"num_warmup_steps\": 50\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"hyperparam_search_config\": {},\n",
    "    \"logger_config\": {}\n",
    "}\n",
    "\n",
    "response_train_model = requests.post(url_train_model, headers=headers_post, json=train_model_data)\n",
    "print(\"Remote Training Status:\", response_train_model.status_code)\n",
    "print(\"Remote Training Response:\", response_train_model.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'job_uuid': 'remote-dpo-training-distilgpt2'}, {'job_uuid': 'remote-dpo-training-distilgpt2-goodrun'}]}\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all post-training jobs\n",
    "# This will show all training jobs that have been submitted to the system\n",
    "\n",
    "url_post_training_jobs = f\"{base_url}/v1/post-training/jobs\"\n",
    "response_post_training_jobs = requests.get(url_post_training_jobs, headers=headers_get)\n",
    "\n",
    "# Display all jobs with their current status and metadata\n",
    "print(response_post_training_jobs.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status: 200\n",
      "Job Status Response: {'job_uuid': 'remote-dpo-training-distilgpt2', 'status': 'completed', 'scheduled_at': '2025-06-22T23:55:13.800574Z', 'started_at': '2025-06-22T23:55:13.801461Z', 'completed_at': '2025-06-22T23:55:22.943639Z', 'resources_allocated': None, 'checkpoints': [{'identifier': 'distilgpt2-dpo-1', 'created_at': '2025-06-22T23:55:22.548906Z', 'epoch': 1, 'post_training_job_id': 'remote-dpo-training-distilgpt2', 'path': '../dpo_checkpoints/dpo_model', 'training_metrics': None}]}\n"
     ]
    }
   ],
   "source": [
    "# Check the status of a specific training job\n",
    "# Replace the job_uuid with the actual UUID from your training job\n",
    "\n",
    "job_uuid = \"remote-dpo-training-distilgpt2\"  # The job UUID from the remote training request\n",
    "url_job_status = f\"{base_url}/v1/post-training/job/status?job_uuid={job_uuid}\"\n",
    "\n",
    "response_job_status = requests.get(url_job_status, headers=headers_get)\n",
    "\n",
    "print(\"Job Status:\", response_job_status.status_code)\n",
    "# The response will include: status, scheduled_at, started_at, completed_at, checkpoints\n",
    "print(\"Job Status Response:\", response_job_status.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
