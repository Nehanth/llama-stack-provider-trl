{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# How to Use Llama Stack TRL Remote Provider\n",
    "\n",
    "This notebook demonstrates how to interact with the Llama Stack TRL Remote Provider for post-training tasks, specifically Direct Preference Optimization (DPO). The remote provider allows you to run training jobs on a separate service while managing them through the Llama Stack API.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The TRL Remote Provider enables you to:\n",
    "- Upload preference datasets for remote training\n",
    "- Submit DPO training jobs to remote TRL service\n",
    "- Monitor remote training progress and retrieve artifacts\n",
    "- Manage distributed post-training workflows through a REST API\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure that:\n",
    "1. The TRL Remote Service is running on `http://localhost:8080`\n",
    "2. The Llama Stack client is running on `http://127.0.0.1:8321`\n",
    "3. You have the required dependencies installed (`requests`)\n",
    "4. The client is configured with the remote TRL provider\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by importing the required libraries and setting up our API configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "\n",
    "# Base URL for the Llama Stack client API\n",
    "# The client connects to the remote TRL service for training\n",
    "base_url = \"http://127.0.0.1:8321\"\n",
    "\n",
    "# Remote TRL service runs on http://localhost:8080\n",
    "# Client forwards training requests to the remote service\n",
    "remote_service_url = \"http://localhost:8080\"\n",
    "\n",
    "# Headers for GET requests (retrieving data)\n",
    "headers_get = {\n",
    "    \"accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Headers for POST requests (sending data)\n",
    "headers_post = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Check Available Providers\n",
    "\n",
    "First, let's verify that our remote TRL provider is properly configured and available. This endpoint will show us all the providers that are currently registered with the Llama Stack client, including the remote TRL provider configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'api': 'post_training', 'provider_id': 'trl_remote', 'provider_type': 'remote::trl', 'config': {'base_url': 'http://localhost:8080', 'timeout': 3600, 'connect_timeout': 30, 'max_retries': 3, 'retry_delay': 5, 'training_config': {'device': 'cuda', 'dpo_beta': 0.1, 'use_reference_model': True, 'max_seq_length': 2048, 'gradient_checkpointing': False, 'logging_steps': 10, 'warmup_ratio': 0.1, 'weight_decay': 0.01}}, 'health': {'status': 'Not Implemented', 'message': 'Provider does not implement health check'}}, {'api': 'datasetio', 'provider_id': 'localfs', 'provider_type': 'inline::localfs', 'config': {'kvstore': {'type': 'sqlite', 'db_path': '/tmp/llama_stack_provider_trl_remote/datasetio.db'}}, 'health': {'status': 'Not Implemented', 'message': 'Provider does not implement health check'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Get the list of available providers\n",
    "# This will show us what services are available (remote TRL for post-training, localfs for datasets, etc.)\n",
    "\n",
    "url_providers = f\"{base_url}/v1/providers\"\n",
    "response_providers = requests.get(url_providers, headers=headers_get)\n",
    "\n",
    "# Display the providers and their configurations\n",
    "# You should see 'remote::trl' provider for post-training and 'localfs' for dataset storage\n",
    "print(response_providers.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Working with Datasets\n",
    "\n",
    "For remote DPO training, we need preference datasets that contain prompts with both \"chosen\" (preferred) and \"rejected\" responses. Datasets are stored locally but sent to the remote training service during job execution. Let's first check what datasets are currently available in our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'identifier': 'dataset-181c39ce-d135-48dc-86d8-158cfe7d231b', 'provider_resource_id': 'dataset-181c39ce-d135-48dc-86d8-158cfe7d231b', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is 2+2?', 'chosen': '2+2 equals 4. This is basic arithmetic.', 'rejected': 'I dont know math.'}, {'prompt': 'What is the capital of France?', 'chosen': 'Paris is the capital city of France.', 'rejected': 'Dunno.'}, {'prompt': 'What is artificial intelligence?', 'chosen': 'AI is the simulation of human intelligence by machines.', 'rejected': 'No idea what that is.'}, {'prompt': 'What color is the sky?', 'chosen': 'The sky appears blue during clear weather.', 'rejected': 'I dont know colors.'}, {'prompt': 'What is the largest planet?', 'chosen': 'Jupiter is the largest planet in our solar system.', 'rejected': 'Not sure about planets.'}, {'prompt': 'Who wrote Hamlet?', 'chosen': 'William Shakespeare wrote Hamlet.', 'rejected': 'I dont know literature.'}, {'prompt': 'What is water made of?', 'chosen': 'Water is composed of hydrogen and oxygen (H2O).', 'rejected': 'Not sure about chemistry.'}, {'prompt': 'What is the speed of light?', 'chosen': 'Light travels at approximately 299,792,458 meters per second.', 'rejected': 'I dont know physics.'}, {'prompt': 'What is gravity?', 'chosen': 'Gravity is the force that attracts objects toward each other.', 'rejected': 'No clue about forces.'}, {'prompt': 'What is the smallest unit of matter?', 'chosen': 'Atoms are the basic units of matter.', 'rejected': 'Dunno about matter.'}, {'prompt': 'How many continents are there?', 'chosen': 'There are seven continents on Earth.', 'rejected': 'I dont know geography.'}, {'prompt': 'What is photosynthesis?', 'chosen': 'Photosynthesis is how plants convert sunlight into energy.', 'rejected': 'Not sure about plants.'}]}, 'metadata': {}}, {'identifier': 'remote-dpo-test', 'provider_resource_id': 'remote-dpo-test', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is the capital of France?', 'chosen': 'Paris is the capital of France.', 'rejected': 'I dont know.'}, {'prompt': 'What is 2+2?', 'chosen': '2+2 equals 4.', 'rejected': 'I dont know math.'}]}, 'metadata': {}}, {'identifier': 'remote-dpo-test-dataset', 'provider_resource_id': 'remote-dpo-test-dataset', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is the capital of France?', 'chosen': \"The capital of France is Paris. Paris is the largest city in France and serves as the country's political, economic, and cultural center.\", 'rejected': 'France capital is Paris.'}, {'prompt': 'Explain machine learning briefly', 'chosen': 'Machine learning is a subset of artificial intelligence where algorithms learn patterns from data to make predictions or decisions without being explicitly programmed for each specific task.', 'rejected': 'ML is when computers learn stuff from data.'}, {'prompt': 'Write a simple Python function to add two numbers', 'chosen': 'Here\\'s a simple Python function to add two numbers:\\n\\n```python\\ndef add_numbers(a, b):\\n    \"\"\"\\n    Add two numbers and return the result.\\n    \\n    Args:\\n        a: First number\\n        b: Second number\\n    \\n    Returns:\\n        Sum of a and b\\n    \"\"\"\\n    return a + b\\n```', 'rejected': 'def add(x,y): return x+y'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Remote TRL DPO test dataset'}}, {'identifier': 'test-dpo-dataset-distilgpt2', 'provider_resource_id': 'test-dpo-dataset-distilgpt2', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is machine learning?', 'chosen': 'Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve their performance on specific tasks without being explicitly programmed. It uses algorithms to find patterns in data and make predictions or decisions.', 'rejected': 'Machine learning is just computers doing math stuff with data.'}, {'prompt': 'Write a hello world program', 'chosen': 'Here is a simple hello world program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```', 'rejected': 'print hello world'}, {'prompt': 'Explain the concept of fine-tuning', 'chosen': 'Fine-tuning is the process of taking a pre-trained model and further training it on a specific dataset to adapt it for a particular task or domain while leveraging its existing knowledge. This approach is more efficient than training from scratch.', 'rejected': 'Fine-tuning means making a model better by training it more.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Inline DPO preference training dataset for DistilGPT-2'}}, {'identifier': 'test-dpo-dataset-remote', 'provider_resource_id': 'test-dpo-dataset-remote', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is machine learning?', 'chosen': 'Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve their performance on specific tasks without being explicitly programmed. It uses algorithms to find patterns in data and make predictions or decisions.', 'rejected': 'Machine learning is just computers doing math stuff with data.'}, {'prompt': 'Write a hello world program', 'chosen': 'Here is a simple hello world program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```', 'rejected': 'print hello world'}, {'prompt': 'Explain the concept of fine-tuning', 'chosen': 'Fine-tuning is the process of taking a pre-trained model and further training it on a specific dataset to adapt it for a particular task or domain while leveraging its existing knowledge. This approach is more efficient than training from scratch.', 'rejected': 'Fine-tuning means making a model better by training it more.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Remote DPO preference training dataset'}}]}\n"
     ]
    }
   ],
   "source": [
    "# List all available datasets in the system\n",
    "# This will show existing datasets that can be used for training\n",
    "\n",
    "url_datasets = f\"{base_url}/v1/datasets\"\n",
    "response_datasets = requests.get(url_datasets, headers=headers_get)\n",
    "\n",
    "# Display the datasets - each dataset should have a purpose (e.g., 'post-training/messages')\n",
    "# and a source containing the training data\n",
    "print(response_datasets.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.1 Upload a DPO Dataset\n",
    "\n",
    "Now let's create and upload a preference dataset for remote DPO training. This dataset contains examples of prompts with both \"chosen\" (high-quality) and \"rejected\" (low-quality) responses. When training starts, this dataset will be sent to the remote TRL service for processing.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- `prompt`: The input question or instruction\n",
    "- `chosen`: The preferred/high-quality response\n",
    "- `rejected`: The less preferred/low-quality response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Upload Status: 200\n",
      "Dataset Upload Response: {'identifier': 'test-dpo-dataset-remote', 'provider_resource_id': 'test-dpo-dataset-remote', 'provider_id': 'localfs', 'type': 'dataset', 'owner': {'principal': '', 'attributes': {}}, 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is machine learning?', 'chosen': 'Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve their performance on specific tasks without being explicitly programmed. It uses algorithms to find patterns in data and make predictions or decisions.', 'rejected': 'Machine learning is just computers doing math stuff with data.'}, {'prompt': 'Write a hello world program', 'chosen': 'Here is a simple hello world program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```', 'rejected': 'print hello world'}, {'prompt': 'Explain the concept of fine-tuning', 'chosen': 'Fine-tuning is the process of taking a pre-trained model and further training it on a specific dataset to adapt it for a particular task or domain while leveraging its existing knowledge. This approach is more efficient than training from scratch.', 'rejected': 'Fine-tuning means making a model better by training it more.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Remote DPO preference training dataset'}}\n"
     ]
    }
   ],
   "source": [
    "# Upload a DPO dataset for remote training\n",
    "# This creates a preference dataset that will be sent to the remote TRL service\n",
    "\n",
    "url_upload_dataset = f\"{base_url}/v1/datasets\"\n",
    "\n",
    "# Define the dataset payload with preference pairs\n",
    "dataset_payload = {\n",
    "    \"dataset_id\": \"test-dpo-dataset-remote\",\n",
    "    \"purpose\": \"post-training/messages\",             \n",
    "    \"dataset_type\": \"preference\",                    \n",
    "    \"source\": {\n",
    "        \"type\": \"rows\",                              \n",
    "        \"rows\": [\n",
    "            {\n",
    "\n",
    "                \"prompt\": \"What is machine learning?\",\n",
    "                \"chosen\": \"Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve their performance on specific tasks without being explicitly programmed. It uses algorithms to find patterns in data and make predictions or decisions.\",\n",
    "                \"rejected\": \"Machine learning is just computers doing math stuff with data.\"\n",
    "            },\n",
    "            {\n",
    "\n",
    "                \"prompt\": \"Write a hello world program\",\n",
    "                \"chosen\": \"Here is a simple hello world program in Python:\\n\\n```python\\nprint(\\\"Hello, World!\\\")\\n```\",\n",
    "                \"rejected\": \"print hello world\"\n",
    "            },\n",
    "            {\n",
    "                \"prompt\": \"Explain the concept of fine-tuning\",\n",
    "                \"chosen\": \"Fine-tuning is the process of taking a pre-trained model and further training it on a specific dataset to adapt it for a particular task or domain while leveraging its existing knowledge. This approach is more efficient than training from scratch.\",\n",
    "                \"rejected\": \"Fine-tuning means making a model better by training it more.\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"provider_id\": \"localfs\",                    # Use local filesystem storage\n",
    "        \"description\": \"Remote DPO preference training dataset\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Send the POST request to upload the dataset\n",
    "response_dataset = requests.post(url_upload_dataset, headers=headers_post, json=dataset_payload)\n",
    "print(\"Dataset Upload Status:\", response_dataset.status_code)\n",
    "print(\"Dataset Upload Response:\", response_dataset.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.2 Verify Dataset Upload\n",
    "\n",
    "Let's confirm that our dataset was successfully uploaded and is now available in the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'identifier': 'dataset-181c39ce-d135-48dc-86d8-158cfe7d231b', 'provider_resource_id': 'dataset-181c39ce-d135-48dc-86d8-158cfe7d231b', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is 2+2?', 'chosen': '2+2 equals 4. This is basic arithmetic.', 'rejected': 'I dont know math.'}, {'prompt': 'What is the capital of France?', 'chosen': 'Paris is the capital city of France.', 'rejected': 'Dunno.'}, {'prompt': 'What is artificial intelligence?', 'chosen': 'AI is the simulation of human intelligence by machines.', 'rejected': 'No idea what that is.'}, {'prompt': 'What color is the sky?', 'chosen': 'The sky appears blue during clear weather.', 'rejected': 'I dont know colors.'}, {'prompt': 'What is the largest planet?', 'chosen': 'Jupiter is the largest planet in our solar system.', 'rejected': 'Not sure about planets.'}, {'prompt': 'Who wrote Hamlet?', 'chosen': 'William Shakespeare wrote Hamlet.', 'rejected': 'I dont know literature.'}, {'prompt': 'What is water made of?', 'chosen': 'Water is composed of hydrogen and oxygen (H2O).', 'rejected': 'Not sure about chemistry.'}, {'prompt': 'What is the speed of light?', 'chosen': 'Light travels at approximately 299,792,458 meters per second.', 'rejected': 'I dont know physics.'}, {'prompt': 'What is gravity?', 'chosen': 'Gravity is the force that attracts objects toward each other.', 'rejected': 'No clue about forces.'}, {'prompt': 'What is the smallest unit of matter?', 'chosen': 'Atoms are the basic units of matter.', 'rejected': 'Dunno about matter.'}, {'prompt': 'How many continents are there?', 'chosen': 'There are seven continents on Earth.', 'rejected': 'I dont know geography.'}, {'prompt': 'What is photosynthesis?', 'chosen': 'Photosynthesis is how plants convert sunlight into energy.', 'rejected': 'Not sure about plants.'}]}, 'metadata': {}}, {'identifier': 'remote-dpo-test', 'provider_resource_id': 'remote-dpo-test', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is the capital of France?', 'chosen': 'Paris is the capital of France.', 'rejected': 'I dont know.'}, {'prompt': 'What is 2+2?', 'chosen': '2+2 equals 4.', 'rejected': 'I dont know math.'}]}, 'metadata': {}}, {'identifier': 'remote-dpo-test-dataset', 'provider_resource_id': 'remote-dpo-test-dataset', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is the capital of France?', 'chosen': \"The capital of France is Paris. Paris is the largest city in France and serves as the country's political, economic, and cultural center.\", 'rejected': 'France capital is Paris.'}, {'prompt': 'Explain machine learning briefly', 'chosen': 'Machine learning is a subset of artificial intelligence where algorithms learn patterns from data to make predictions or decisions without being explicitly programmed for each specific task.', 'rejected': 'ML is when computers learn stuff from data.'}, {'prompt': 'Write a simple Python function to add two numbers', 'chosen': 'Here\\'s a simple Python function to add two numbers:\\n\\n```python\\ndef add_numbers(a, b):\\n    \"\"\"\\n    Add two numbers and return the result.\\n    \\n    Args:\\n        a: First number\\n        b: Second number\\n    \\n    Returns:\\n        Sum of a and b\\n    \"\"\"\\n    return a + b\\n```', 'rejected': 'def add(x,y): return x+y'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Remote TRL DPO test dataset'}}, {'identifier': 'test-dpo-dataset-distilgpt2', 'provider_resource_id': 'test-dpo-dataset-distilgpt2', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is machine learning?', 'chosen': 'Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve their performance on specific tasks without being explicitly programmed. It uses algorithms to find patterns in data and make predictions or decisions.', 'rejected': 'Machine learning is just computers doing math stuff with data.'}, {'prompt': 'Write a hello world program', 'chosen': 'Here is a simple hello world program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```', 'rejected': 'print hello world'}, {'prompt': 'Explain the concept of fine-tuning', 'chosen': 'Fine-tuning is the process of taking a pre-trained model and further training it on a specific dataset to adapt it for a particular task or domain while leveraging its existing knowledge. This approach is more efficient than training from scratch.', 'rejected': 'Fine-tuning means making a model better by training it more.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Inline DPO preference training dataset for DistilGPT-2'}}, {'identifier': 'test-dpo-dataset-remote', 'provider_resource_id': 'test-dpo-dataset-remote', 'provider_id': 'localfs', 'type': 'dataset', 'purpose': 'post-training/messages', 'source': {'type': 'rows', 'rows': [{'prompt': 'What is machine learning?', 'chosen': 'Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve their performance on specific tasks without being explicitly programmed. It uses algorithms to find patterns in data and make predictions or decisions.', 'rejected': 'Machine learning is just computers doing math stuff with data.'}, {'prompt': 'Write a hello world program', 'chosen': 'Here is a simple hello world program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```', 'rejected': 'print hello world'}, {'prompt': 'Explain the concept of fine-tuning', 'chosen': 'Fine-tuning is the process of taking a pre-trained model and further training it on a specific dataset to adapt it for a particular task or domain while leveraging its existing knowledge. This approach is more efficient than training from scratch.', 'rejected': 'Fine-tuning means making a model better by training it more.'}]}, 'metadata': {'provider_id': 'localfs', 'description': 'Remote DPO preference training dataset'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Verify that our dataset was successfully uploaded\n",
    "# This should now show our \"test-dpo-dataset-inline-large\" dataset\n",
    "\n",
    "url_datasets = f\"{base_url}/v1/datasets\"\n",
    "response_datasets = requests.get(url_datasets, headers=headers_get)\n",
    "\n",
    "# The response should include our uploaded dataset with all the preference pairs\n",
    "print(response_datasets.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Submitting Remote DPO Training Jobs\n",
    "\n",
    "Now that we have our dataset ready, let's submit a DPO training job to the remote TRL service. The Llama Stack client will forward this request to the remote service running on port 8080, which will execute the actual training.\n",
    "\n",
    "**Key Parameters for Remote Training:**\n",
    "- `model`: The base model to fine-tune (e.g., granite-3.3-2b-base, distilgpt2)\n",
    "- `algorithm_config`: Sent as LoRA format (client validation) but converted to DPO by remote service\n",
    "- `training_config`: Standard training parameters like learning rate, epochs, batch size\n",
    "- `dataset_id`: The preference dataset that will be sent to the remote service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote Training Status: 200\n",
      "Remote Training Response: {'job_uuid': 'remote-dpo-training-distilgpt2'}\n"
     ]
    }
   ],
   "source": [
    "# Submit DPO training job to remote TRL service\n",
    "# The client sends this to the remote service for execution\n",
    "\n",
    "url_train_model = f\"{base_url}/v1/post-training/preference-optimize\"\n",
    "\n",
    "train_model_data = {\n",
    "    \"job_uuid\": \"remote-dpo-training-distilgpt2\",\n",
    "    \"model\": \"distilgpt2\",  # Using smaller model for faster remote training\n",
    "    \"finetuned_model\": \"dpo-distilgpt2-remote\",\n",
    "    \"checkpoint_dir\": \"../dpo_checkpoints\",\n",
    "    # NOTE: Client requires LoRA format but remote service converts to DPO\n",
    "    \"algorithm_config\": {\n",
    "        \"type\": \"LoRA\",\n",
    "        \"lora_attn_modules\": [\"attn\"],\n",
    "        \"apply_lora_to_mlp\": False,\n",
    "        \"apply_lora_to_output\": False,\n",
    "        \"rank\": 16,\n",
    "        \"alpha\": 32\n",
    "    },\n",
    "    \"training_config\": {    \n",
    "        \"n_epochs\": 1,\n",
    "        \"max_steps_per_epoch\": 10,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"data_config\": {\n",
    "            \"dataset_id\": \"test-dpo-dataset-remote\",\n",
    "            \"batch_size\": 2,\n",
    "            \"shuffle\": True,\n",
    "            \"data_format\": \"instruct\"\n",
    "        },\n",
    "        \"optimizer_config\": {\n",
    "            \"optimizer_type\": \"adamw\",\n",
    "            \"lr\": 1e-5,\n",
    "            \"lr_scheduler_type\": \"linear\",\n",
    "            \"warmup_steps\": 10,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"num_warmup_steps\": 5\n",
    "        }\n",
    "    },\n",
    "    \"hyperparam_search_config\": {},\n",
    "    \"logger_config\": {}\n",
    "}\n",
    "\n",
    "# This request goes: Client -> Llama Stack -> Remote TRL Service\n",
    "response_train_model = requests.post(url_train_model, headers=headers_post, json=train_model_data)\n",
    "print(\"Remote Training Status:\", response_train_model.status_code)\n",
    "print(\"Remote Training Response:\", response_train_model.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Monitoring Remote Training Jobs\n",
    "\n",
    "Once a remote training job is submitted, you can monitor its progress through the Llama Stack client. The client communicates with the remote TRL service to get job status and artifacts. Training jobs go through various states: `scheduled`, `in_progress`, `completed`, or `failed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'job_uuid': 'remote-dpo-training-distilgpt2'}]}\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all post-training jobs\n",
    "# This will show all training jobs that have been submitted to the system\n",
    "\n",
    "url_post_training_jobs = f\"{base_url}/v1/post-training/jobs\"\n",
    "response_post_training_jobs = requests.get(url_post_training_jobs, headers=headers_get)\n",
    "\n",
    "# Display all jobs with their current status and metadata\n",
    "print(response_post_training_jobs.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.1 Check Specific Job Status\n",
    "\n",
    "You can get detailed information about a specific training job using its job UUID. This is useful for monitoring progress and checking when training is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status: 200\n",
      "Job Status Response: {'job_uuid': 'remote-dpo-training-distilgpt2', 'status': 'completed', 'scheduled_at': '2025-06-22T23:55:13.800574Z', 'started_at': '2025-06-22T23:55:13.801461Z', 'completed_at': '2025-06-22T23:55:22.943639Z', 'resources_allocated': None, 'checkpoints': [{'identifier': 'distilgpt2-dpo-1', 'created_at': '2025-06-22T23:55:22.548906Z', 'epoch': 1, 'post_training_job_id': 'remote-dpo-training-distilgpt2', 'path': '../dpo_checkpoints/dpo_model', 'training_metrics': None}]}\n"
     ]
    }
   ],
   "source": [
    "# Check the status of a specific training job\n",
    "# Replace the job_uuid with the actual UUID from your training job\n",
    "\n",
    "job_uuid = \"remote-dpo-training-distilgpt2\"  # The job UUID from the remote training request\n",
    "url_job_status = f\"{base_url}/v1/post-training/job/status?job_uuid={job_uuid}\"\n",
    "\n",
    "response_job_status = requests.get(url_job_status, headers=headers_get)\n",
    "\n",
    "print(\"Job Status:\", response_job_status.status_code)\n",
    "# The response will include: status, scheduled_at, started_at, completed_at, checkpoints\n",
    "print(\"Job Status Response:\", response_job_status.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.2 Retrieve Training Artifacts\n",
    "\n",
    "After training is complete (or during training), you can retrieve the artifacts generated by the job, including model checkpoints and training metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Artifacts Status: 200\n",
      "Job Artifacts Response: {'job_uuid': 'remote-dpo-training-distilgpt2', 'checkpoints': [{'identifier': 'distilgpt2-dpo-1', 'created_at': '2025-06-22T23:55:22.548906Z', 'epoch': 1, 'post_training_job_id': 'remote-dpo-training-distilgpt2', 'path': '../dpo_checkpoints/dpo_model', 'training_metrics': None}]}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve artifacts (checkpoints, metrics) from a completed training job\n",
    "# This will show available model checkpoints and their metadata\n",
    "\n",
    "url_job_artifacts = f\"{base_url}/v1/post-training/job/artifacts?job_uuid={job_uuid}\"\n",
    "response_job_artifacts = requests.get(url_job_artifacts, headers=headers_get)\n",
    "\n",
    "print(\"Job Artifacts Status:\", response_job_artifacts.status_code)\n",
    "# The response will include checkpoint information: identifier, path, epoch, training_metrics\n",
    "print(\"Job Artifacts Response:\", response_job_artifacts.json())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete workflow for using the Llama Stack TRL Remote Provider:\n",
    "\n",
    "1. **Setup**: Configure API endpoints for client and remote service\n",
    "2. **Provider Verification**: Check that remote TRL and localfs providers are available\n",
    "3. **Dataset Management**: Upload preference datasets for remote DPO training\n",
    "4. **Remote Training**: Submit DPO training jobs to remote TRL service\n",
    "5. **Job Monitoring**: Track remote training progress and status\n",
    "6. **Artifact Retrieval**: Access trained model checkpoints and metrics from remote service\n",
    "\n",
    "### Remote Provider Architecture\n",
    "\n",
    "```\n",
    "Client Request -> Llama Stack (8321) -> Remote TRL Service (8080) -> DPO Training\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Use the trained model**: Load the checkpoints from the remote service checkpoint directory\n",
    "- **Experiment with parameters**: Try different configurations for remote training\n",
    "- **Scale up**: Use larger datasets and models with the remote service\n",
    "- **Deploy remotely**: Run multiple training services on different machines\n",
    "\n",
    "### Troubleshooting Tips\n",
    "\n",
    "- **Job already exists error**: Use a unique `job_uuid` for each training run\n",
    "- **Remote service offline**: Check that TRL service is running on port 8080\n",
    "- **Training failures**: Monitor remote service logs for detailed error information\n",
    "- **Memory issues**: Consider using smaller models or adjust remote service resources\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
